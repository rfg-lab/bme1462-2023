{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing and analysis in Python: an introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overview & learning objectives\n",
    "In this notebook, we will discuss (without much detail) how to use Python to analyze biological images. As a \"vertebrating\" example, we will quantify the morphology of cells in developing fruit fly embryos. Specifically, you will learn how to open and display images, apply basic filters, segment individual cells, quantify their size and shape, and visualize the results. \n",
    "\n",
    "This notebook also serves as a model of what you are expected to do when it is your turn to present in BME1462. \n",
    "\n",
    "With this notebook you will:\n",
    "\n",
    "1. Gain an understanding of how to represent images in Python and numpy.\n",
    "\n",
    "1. Learn the basic steps of a complex image segmentation procedure. \n",
    "\n",
    "1. Experiment with filtering, thresholding, mathematical morphology, and watershed-based segmentation.\n",
    "\n",
    "1. Measure cells in images and display the results.\n",
    "\n",
    "Please, **note** that this notebook is not an exhaustive introduction to Python, numpy, scikit-image, or matplotlib. For tutorials and official documentation, please check at the [end of this notebook](#additional_materials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Images as Python lists\n",
    "In this section, we will discuss the basic Python tools necessary to process and analyze images. \n",
    "\n",
    "We will consider a two-dimensional image as a matrix in which each element contains the corresponding pixel value. In Python, **matrices can be represented as lists of lists**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n"
     ]
    }
   ],
   "source": [
    "alist = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]  # square brackets define lists in Python.\n",
    "\n",
    "print(alist)  # the print command can be useful to visualize the contents of Python variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "represents a matrix with four rows and three columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Images in numpy: the ndarray\n",
    "Python is not really good at working with matrices. Fortunately, the **numpy** package provides highly optimized methods to work with multidimensional arrays. At the core of numpy is the **ndarray** data structure, used to store and manipulate arrays. You can use the Python help system to learn more about ndarrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  # loads the numpy package.\n",
    "\n",
    "# a question mark invokes the Python help system.\n",
    "numpy.ndarray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to create an ndarray from a list using the numpy method **asarray**.\n",
    "\n",
    "Use the help system to figure out how to create an ndarray from **alist**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.ndarray?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrays have two important properties, **shape** and **dtype**. \n",
    "\n",
    "In your own words, explain what each one of these two properties mean and report the values for the ndarray that you just created above. Remember that you can always use the help system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**shape**: \n",
    "\n",
    "**dtype**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Opening and displaying images\n",
    "The **scikit-image** package uses ndarrays to represent images. scikit-image builds efficient routines for image processing and analysis around ndarrays. \n",
    "\n",
    "Most often we will not be \"creating\" images, but opening them from a file. In scikit-image, the **io** module provides the method **imread**, which can be used to open images. \n",
    "\n",
    "Import the io module with the following command (**skimage** is short for scikit-image), and use the imread method to read the image **cells.tif**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "# load cells.tif here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **matplotlib** package provides functionality to display images and plot data. If you are familiar with Matlab, the matplotlib method names will result familiar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#print(plt.style.available)  # prints all the matplotlib styles that can be used.\n",
    "plt.style.use(['classic', 'grayscale', 'bmh'])\n",
    "plt.grid(False)\n",
    "\n",
    "plt.imshow(animage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Accessing pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because images are numpy ndarrays, we can use them as we would use an ndarray. For example, we can access the value of the pixel at coordinates (x, y) = (25, 33) by using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animage[33, 25])  # 2D ndarrays are accessed using [row, col] pairs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create a new image using just every other row and column from the top-left corner of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topleft_subsampled = animage[0:60:2, 0:60:2].copy()  # select rows and columns from 0 to 60, with a step of 2 (every other).\n",
    "\n",
    "plt.imshow(topleft_subsampled)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based, on what we have learned so far, answer the following questions. Remember that the help system is your friend!\n",
    "\n",
    "1. What are the dimensions of the new image that we created?\n",
    "\n",
    "2. How would you create a copy of a 50x50 subimage on the top right corner of the image? And if you wanted to take one in every three rows, and every single column?\n",
    "\n",
    "3. Is the call to copy() necessary? Why are we using it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to use numpy methods on images is really powerful. For example, thresholding can be easily accomplished by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask = animage > 150  # this creates a new array, notice the data type!!\n",
    "\n",
    "print(amask)\n",
    "\n",
    "plt.imshow(amask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Filtering\n",
    "As an example of the use of scikit-image, let's try and segment the outlines of the cells in **animage**. To make sure that the image is the original one, load the image from disk again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of many segmentation pipelines is to blur the image. The idea is to smooth out noise, \"flatten\" the background, and increase the continuity of boundaries between objects. A common way to blur an image is to apply a **Gaussian filter**. In Gaussian filtering, each pixel value is substituted by a (Gaussian-) weighted average of its neighbouring pixels. \n",
    "\n",
    "The scikit-image module **filters** contains methods to filter images. Import the filters module and examine the function **filters.gaussian**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use skimage.filters.gaussian to smoothen animage. Based on the goals of smoothing the input image mentioned above, can you think of a good value for the sigma parameter? Why did you choose that value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the pixel values in the smooth image. What is different about them? Can you think of strategies to normalize those values and use at least 8-bits per pixel? The method **skimage.exposure.rescale_intensity** may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good input image, let's consider our segmentation strategy. A very common approach to segment touching objects is the **watershed algorithm**. The watershed algorithm is a **region-growing method** which begins with the identification of one point or seed per object. The watershed grows seeds to find the boundaries of the object, and therefore it is important to have one -and only one- seed per object to be segmented.\n",
    "\n",
    "To use the watershed algorithm in our image, we need to identify one (and only one) seed per cell. We will do that by identifying pixels buried deep within the cytoplasm of each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To distinguish interfacial and cytoplasmic pixels, we can simply threshold our image. Can you find a good threshold value? If yes, which one? If not, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper thresholding often requires setting a different threshold value per pixel. This is known as **adaptive or local thresholding**. In local thresholding, the threshold value at each pixel depends on the neighbouring pixels (e.g. it is the mean of the pixels within a 3x3 window around each pixel). In scikit-image, local thresholding can be accomplished with the method **skimage.filters.threshold_local**.\n",
    "\n",
    "Consult the documentation for threshold_local, and use local thresholding to obtain an accurate seggregation between interfacial and cytoplasmic pixels in the image above. What parameters did you use? Which ones did not work? How is the result different from the result using a single threshold for the entire image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Mathematical morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks resulting from a threshold are rarely perfect. Depending on the threshold selection, too many or too few pixels will be considered to be \"foreground\", creating extraneous objects, holes, or discontinuities.\n",
    "\n",
    "Mathematical morphology provides tools to \"fix\" thresholded images. Mathematical morphology is a discipline based on set theory that enables manipulation and analysis of geometric structures. Mathematical morphology deals with sets of pixels above or below the threshold value. **Erosion, dilation, opening or closing** are some mathematical morphology operations. Similar to our discussion of local thresholds, in morphological operations the value of each pixel (on/off) is determined based on the status (on/off) of a set of neighbours. The set of neighbours that affect the value of any given pixel is determined by a structuring element, a \"mask\" that is overlaid on each pixel of the original image. Pixels that are \"on\" in the structuring element are taken into account in the calculation of the new pixel value. Manipulating the size and shape of the structuring element can therefore have dramatic consequences in the results of morphological operations.  \n",
    "\n",
    "**Opening and closing**, specifically, can be useful to process binary images: opening separates fused objects, and closing fills holes in objects. Opening and closing are implemented in the methods **skimage.morphology.binary_opening and skimage.morphology.binary_closing**, respectively. \n",
    "\n",
    "Depending on your choice of threshold, use opening or closing to improve the mask that you generated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Finding seeds: the distance transform\n",
    "\n",
    "Now that we have a good representation of interfacial pixels, let's find pixels **away** from interfaces. The **distance transform** of a binary image is an image in which the value of each pixel corresponds to its distance to the background. In general, the distance transform can be calculated by iteratively eroding an image until there are no \"on\" pixels left. The distance transform value of a pixel corresponds to the number of the erosion in which the pixel disappeared.\n",
    "\n",
    "We can use the distance transform to identify pixels far from cell interfaces. We will use a method in the scipy.ndimage module to calculate the distance transform, **distance_transform_edt**. scikit-image provides its own method to calculate the distance transform (skimage.morphology.medial_axis), but that function does many more things, and using it here is overkill.\n",
    "\n",
    "Use distance_transform_edt to calculate the distance transform of the mask above. Remember, we are trying to find the distance from any given pixel to the cell interfaces ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to obtain one and only one seed point per cell. Once we have the distance transform, there are multiple ways to obtain one point per cell. To visualize seeds, let's define a function, **plot_seeds** that plots a list of points over an image. The function also returns an image with the seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seeds(theimage, theseed_coords):\n",
    "    \"\"\"\n",
    "        plot_seeds: plots a set of points on an image.\n",
    "        \n",
    "        input:\n",
    "            theimage: ndarray representing the image.\n",
    "            theseed_coords: ndarray with two columns and as many rows as points to be displayed, \n",
    "                            containing the [y, x] coordinates of each point.     \n",
    "            \n",
    "        output:\n",
    "            seed_image: ndarray representing a labeled image with one object per seed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create empty seed image.\n",
    "    seed_image = numpy.zeros(theimage.shape)\n",
    "\n",
    "    # For each seed ...\n",
    "    for label, seed_xy in enumerate(theseed_coords):\n",
    "        # ... set the value of the corresponding pixel to a different value.\n",
    "        seed_image[seed_xy[0], seed_xy[1]] = label + 1\n",
    "\n",
    "    # Display the image.\n",
    "    plt.imshow(theimage, cmap='gray')\n",
    "    \n",
    "    # Create a structuring element to dilate (aka grow) seeds a bit for display.\n",
    "    structelem = morphology.disk(3)\n",
    "    \n",
    "    # And overlay the seeds.\n",
    "    plt.imshow(morphology.dilation(seed_image, structelem), cmap='jet', alpha=0.50)\n",
    "    plt.show()\n",
    "    \n",
    "    return seed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain one point per cell, we will extract the local maxima of the distance transform. This could be accomplished in different ways. For example, one could threshold the distance tranform to identify pixels that are **at least** a certain distance away from cell interfaces (you could think about how to implement that solution, perhaps using an adaptive threshold). \n",
    "\n",
    "In scikit-image, the skimage.feature module includes the method **peak_local_max**, which can be applied to the distance transform (in combination with the mask that we generated) to obtain one maximum per cell.\n",
    "\n",
    "Using the documentation of **peak_local_max** and **plot_seeds**, extract and visualize a set of seeds for our image. What are the critical parameters to obtain an accurate number of seeds? What are the limitations of peak_local_max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Expanding the seeds: the watershed algorithm\n",
    "\n",
    "We finally have one seed per cell!! The rest is easy. We will grow the seeds using the watershed algorithm.\n",
    "\n",
    "The watershed algorithm simulates a flooding process. The image is interpreted as a surface in which pixel values represent heights. The surface is pierced at the seed points before submerging it in water. As pixels are \"flooded\" (in order of \"height\"), they are assigned to the seed that water came from. scikit-image provides an implementation of the watershed algorithm: **skimage.morphology.watershed**. The **watershed** function returns a **labeled image**, an image in which the value of a pixel indicates the object that the pixel belongs to.\n",
    "\n",
    "Use skimage.morphology.watershed to obtain a labeled image that represents all the objects in the original image. If you feel adventurous, try to display an ovelay of the labeled image and the grayscale image (the code in plot_seeds could serve as inspiration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 How well did we do?\n",
    "\n",
    "We are almost done! Displaying an image overlay of the labeled and the original image is nice, but the colour choices can make it hard to evaluate the segmentation results.\n",
    "\n",
    "Let's define a function, **plot_contours**, that displays the outlines of each object on the original image. We will take advantage of the method **skimage.measure.find_contours**, which extracts isovalued contours at a certain level Below, we just generate one binary image per object and extract isovalued contours at level zero.\n",
    "\n",
    "Complete the docstring for the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import skimage.measure as measure\n",
    "\n",
    "def plot_contours(thegrayimage, thelabeledimage):\n",
    "    \"\"\"\n",
    "        plot_contours: <one-line function description>\n",
    "        \n",
    "        input:\n",
    "            thegrayimage: <one-line parameter description - data type, meaning, etc.>\n",
    "            thelabeledimage: <one-line parameter description - data type, meaning, etc.>    \n",
    "            \n",
    "        output:\n",
    "            ax: <one-line parameter description - data type, meaning, etc.>\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    contour_list = list([])\n",
    "\n",
    "    # Extract contours.\n",
    "    thelabels = numpy.unique(thelabeledimage)\n",
    "    for aLabel in thelabels:\n",
    "        bin_mask = numpy.asarray(thelabeledimage == aLabel,dtype=int)  # skimage.segmentation.find_boundaries can also be used for this.\n",
    "        aContour = measure.find_contours(bin_mask, 0)\n",
    "        aContour = aContour[0]\n",
    "\n",
    "        contour_list.append(aContour)\n",
    "\n",
    "    plt.imshow(thegrayimage, cmap='gray')\n",
    "    ax = plt.gca()\n",
    "    for acontour in contour_list:\n",
    "        ax.add_patch(patches.Polygon(acontour[:, [1, 0]],linewidth=3,edgecolor='r',facecolor='none'))\n",
    "    plt.show()\n",
    "    \n",
    "    return ax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **plot_contours** to display the results of our watershed segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Are the segmentation results accurate? Can you identify cases of over-segmentation (a cell split into two or more) or undersegmentation (two or more cells fused together)? Can you trace those issues back to their root? Why is the segmentation failing in those cases? Can you think about strategies to alleviate those issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Image measurement\n",
    "\n",
    "Our last step is to measure the cells. The method **skimage.measure.regionprops** is an excellent tool to do this. Take a look at its documentation. Under the **Notes** section there is a list of features that regionprops measures, including area, perimeter, pixel value, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use regionprops to measure all the cells in an image. The measurements can be accessed and collected into convenient lists like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Measure labeled image.\n",
    "cell_props = measure.regionprops(labels)  \n",
    "\n",
    "# Define two empty lists to store areas and perimeters.\n",
    "cell_areas = []\n",
    "cell_perimeters = []\n",
    "\n",
    "# Loop through the measurements for each cell ...\n",
    "for acell in cell_props:\n",
    "    # ... and store both area and perimeter in the corresponding lists.\n",
    "    cell_areas.append(acell.area)\n",
    "    cell_perimeters.append(acell.perimeter)\n",
    "\n",
    "# Print the area and perimeter measurements.\n",
    "print(cell_areas)\n",
    "print(cell_perimeters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Data visualization\n",
    "\n",
    "Plotting measurement results is often more useful that printing each one of the measurements. We will use **matplotlib** to generate plots. Below is an example from the [matplotlib website](https://matplotlib.org/2.0.0/examples/statistics/boxplot_vs_violin_demo.html) that generates a violin and a box plot for random, test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "\n",
    "# generate some random test data\n",
    "all_data = [numpy.random.normal(0, std, 100) for std in range(6, 10)]\n",
    "\n",
    "# plot violin plot\n",
    "axes[0].violinplot(all_data,\n",
    "                   showmeans=False,\n",
    "                   showmedians=True)\n",
    "axes[0].set_title('violin plot')\n",
    "\n",
    "# plot box plot\n",
    "axes[1].boxplot(all_data)\n",
    "axes[1].set_title('box plot')\n",
    "\n",
    "# adding horizontal grid lines\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks([y+1 for y in range(len(all_data))])\n",
    "    ax.set_xlabel('xlabel')\n",
    "    ax.set_ylabel('ylabel')\n",
    "\n",
    "# add x-tick labels\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "         xticklabels=['x1', 'x2', 'x3', 'x4'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code above as guide to generate a figure with two plots, each of them comparing area and perimeter for the cells in the original image, displayed as a violin plot on the left, and as a box plot on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='additional_materials'></a>\n",
    "### 10. Additional materials\n",
    "\n",
    "#### 10.1 Tutorials\n",
    "* Python: https://scipy-lectures.org/intro/language/python_language.html\n",
    "* numpy: https://scipy-lectures.org/intro/numpy/index.html\n",
    "* scikit-image: https://scipy-lectures.org/packages/scikit-image/index.html\n",
    "* matplotlib: https://scipy-lectures.org/intro/matplotlib/index.html\n",
    "\n",
    "#### 10.2 Documentation\n",
    "* Python: https://docs.python.org/3/\n",
    "* numpy: https://numpy.org/doc/\n",
    "* scikit-image: https://scikit-image.org/docs/dev/\n",
    "* matplotlib: https://matplotlib.org/3.1.1/contents.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

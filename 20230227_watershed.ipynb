{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation: the watershed algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overview & learning objectives\n",
    "In this notebook we will finally segment cells. That will also give us some objects to measure later on. \n",
    "\n",
    "With this notebook we will:\n",
    "\n",
    "1. Learn about the watershed algorithm for image segmentation.\n",
    "\n",
    "1. Apply watershed-based segmentation to identify cell boundaries.\n",
    "\n",
    "1. Evaluate the results and limitations of the watershed method and discuss how to overcome issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Finding seeds\n",
    "Last time we managed to identify one point per cell. Run this code to reproduce what we did so far:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage import exposure, filters, feature, io, morphology\n",
    "\n",
    "# Read image from disk.\n",
    "animage = io.imread('cells.tif')\n",
    "\n",
    "# Gaussian smoothing to facilitate edge detection.\n",
    "animage_smooth = filters.gaussian(animage, sigma=2, preserve_range=True)\n",
    "\n",
    "# Contrast stretch.\n",
    "animage_rescaled = exposure.rescale_intensity(\n",
    "    animage_smooth, out_range=numpy.uint8)\n",
    "\n",
    "# Local threshold.\n",
    "amask = animage_rescaled >= filters.threshold_local(\n",
    "    animage_rescaled, 33, method='gaussian')\n",
    "\n",
    "# Closing\n",
    "amask_closed = morphology.binary_closing(amask, morphology.disk(3))\n",
    "\n",
    "# Distance transform.\n",
    "dt = ndimage.distance_transform_edt(numpy.invert(amask_closed))\n",
    "\n",
    "# Seed identification.\n",
    "coords_maxima = feature.peak_local_max(dt, labels=morphology.label(\n",
    "    numpy.invert(amask_closed)), num_peaks_per_label=1, exclude_border=False)\n",
    "\n",
    "# Create seed image.\n",
    "seed_image = numpy.zeros(animage.shape)\n",
    "\n",
    "# For each seed ...\n",
    "for label, seed_xy in enumerate(coords_maxima):\n",
    "    # ... set the value of the corresponding pixel to a different value.\n",
    "    seed_image[seed_xy[0], seed_xy[1]] = label + 1\n",
    "\n",
    "# Display image and seeds.\n",
    "plt.imshow(animage, cmap='Greys_r')\n",
    "plt.imshow(morphology.dilation(seed_image, morphology.disk(3)), cmap='inferno', alpha=0.50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Expanding the seeds: the watershed algorithm\n",
    "\n",
    "We finally have one seed per cell!! The rest is easy. We will grow the seeds using the watershed algorithm. The watershed algorithm is a **region-growing method** which begins with the identification of one point or seed per object. The watershed grows seeds to find the boundaries of the object, and therefore it is important to have one -and only one- seed per object to be segmented.\n",
    "\n",
    "The watershed algorithm simulates a flooding process. The image is interpreted as a surface in which pixel values represent heights. The surface is pierced at the seed points before submerging it in water. As pixels are \"flooded\" (in order of \"height\"), they are assigned to the seed that water came from. scikit-image provides an implementation of the watershed algorithm: **skimage.segmentation.watershed**. The **watershed** function returns a **labeled image**, an image in which the value of a pixel indicates the object that the pixel belongs to.\n",
    "\n",
    "Use skimage.segmentation.watershed to obtain a labeled image that represents all the objects in the original image. If you feel adventurous, try to display an ovelay of the labeled image and the grayscale image (the code in plot_seeds could serve as inspiration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE.\n",
    "from skimage.segmentation import watershed\n",
    "watershed_segm = watershed(animage_rescaled, markers=seed_image, watershed_line=True)\n",
    "\n",
    "# Display image and segmentation results.\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(animage, cmap='Greys_r')\n",
    "axs[1].imshow(watershed_segm, cmap='inferno')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How well did we do?\n",
    "\n",
    "We are almost done! Let's define a function, **plot_contours**, that displays the outlines of each object on the original image. We will take advantage of the method **skimage.measure.find_contours**, which extracts isovalued contours at a certain level. Below, we just generate one binary image per object and extract isovalued contours at level zero.\n",
    "\n",
    "Complete the docstring for the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import skimage.measure as measure\n",
    "\n",
    "def plot_contours(thegrayimage, thelabeledimage):\n",
    "    \"\"\"\n",
    "        plot_contours: <one-line function description>\n",
    "        \n",
    "        input:\n",
    "            thegrayimage: <one-line parameter description - data type, meaning, etc.>\n",
    "            thelabeledimage: <one-line parameter description - data type, meaning, etc.>    \n",
    "            \n",
    "        output:\n",
    "            ax: <one-line parameter description - data type, meaning, etc.>\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    contour_list = list([])\n",
    "\n",
    "    # Extract contours.\n",
    "    thelabels = numpy.unique(thelabeledimage)\n",
    "    for aLabel in thelabels:\n",
    "        bin_mask = numpy.asarray(thelabeledimage == aLabel,dtype=int)  # skimage.segmentation.find_boundaries can also be used for this.\n",
    "        aContour = measure.find_contours(bin_mask, 0)\n",
    "        aContour = aContour[0]\n",
    "\n",
    "        contour_list.append(aContour)\n",
    "\n",
    "    plt.imshow(thegrayimage, cmap='gray')\n",
    "    ax = plt.gca()\n",
    "    for acontour in contour_list:\n",
    "        ax.add_patch(patches.Polygon(acontour[:, [1, 0]],linewidth=3,edgecolor='r',facecolor='none'))\n",
    "    plt.show()\n",
    "    \n",
    "    return ax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use **plot_contours** to display the results of our watershed segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE.\n",
    "\n",
    "plot_contours(animage, watershed_segm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think? Are the segmentation results accurate? Can you identify cases of oversegmentation (a cell split into two or more) or undersegmentation (two or more cells fused together)? Can you trace those issues back to their root? Why is the segmentation failing in those cases? Can you think about strategies to alleviate those issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE THIS TEXT:\n",
    "Most issues are due to problems with seed detection. Over-segmentation (e.g. cell at the top right) is caused by having to many seeds in one object, while undersegmentation (a few examples in cells on the bottom row) is caused by not detecting seeds for some cells.\n",
    "\n",
    "A couple of potential solutions for these issues are:\n",
    "\n",
    "1. Delete objects in contact with the image boundary: they should not be measured any way (they are only partially visible in the image), and they contribute most of the issues.\n",
    "\n",
    "1. Add a step to interactively edit the seeds before growing them with the watershed, thus making sure that all cells have one seed and only one seed. \n",
    "\n",
    "1. Reduce the threshold used to identify local maxima in the distance transform image. Many of the cells touching the edge did get some information in the distance transform, but that was not identified as a seed.\n",
    "\n",
    "1. Grow the seeds in a different image, with perhaps even stronger boundaries (e.g. the gradient of the original image).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

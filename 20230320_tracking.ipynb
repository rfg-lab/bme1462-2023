{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration and tracking: optical flow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overview & learning objectives\n",
    "In this notebook we will learn about registration and tracking, two sides of one common idea. \n",
    "\n",
    "With this notebook we will:\n",
    "\n",
    "1. Learn how to open, display, and interact with 3D images in Jupyter notebooks.\n",
    "\n",
    "1. Use optical flow to register consecutive slices on an image identifying key parameters in the registration process.\n",
    "\n",
    "1. Calculate and visualize optical flow vector fields for subsequent application in tracking. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and browsing 3D images\n",
    "Registration and tracking are two applications of one concept: in image stacks containing multiple slices of a certain sample (Z planes, time points, colours, imaging modalities), it is possible to identify a transformation that maps one slice (or the objects on that slice) onto the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step to learn about registration and tracking is to open an image stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "# Read image from disk.\n",
    "astack = io.imread('cells_movie.tif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look a the dimensions of *astack*: how is this different from other images that we used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS.\n",
    "# Inspect the shape: this is not a 2D image any longer.\n",
    "astack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a helper class to visualize 3D images. This is also a nice example of how to use the **ipywidgets** package to create interactive notebooks.\n",
    "\n",
    "Run the cell below and then use this class to visualize *astack*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ImageSliceViewer3D:\n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D displays volumetric data. \n",
    "    \n",
    "    User can interactively change the slice plane and \n",
    "    the slice number being viewed. \n",
    "\n",
    "    Arguments:\n",
    "    volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('gray'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/2.0.2/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, volume, figsize=(8,8), cmap='gray'):\n",
    "        self.volume = volume\n",
    "        self.figsize = figsize\n",
    "        self.cmap = cmap\n",
    "        plt.set_cmap(cmap)\n",
    "        self.v = [np.min(volume), np.max(volume)]\n",
    "        \n",
    "        # Create interactive widget.\n",
    "        ipyw.interact(self.view_selection, view=ipyw.RadioButtons(\n",
    "            options=['x-y','z-y', 'z-x'], value='x-y', \n",
    "            description='slice plane selection:', disabled=False,\n",
    "            style={'description_width': 'initial'}))\n",
    "    \n",
    "    def view_selection(self, view):\n",
    "        # Transpose the volume to orient according to the slice plane.\n",
    "        orient = {\"x-y\": [0, 1, 2], \"z-x\": [1, 2, 0], \"z-y\": [2, 1, 0]}\n",
    "        self.vol = np.transpose(self.volume, orient[view])\n",
    "        \n",
    "        # Create slider to change slice and link it to the function that plots the slice.\n",
    "        maxZ = self.vol.shape[0] - 1\n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z=ipyw.IntSlider(min=0, max=maxZ, step=1, continuous_update=True, \n",
    "            description='Image Slice:'))\n",
    "        \n",
    "    def plot_slice(self, z):\n",
    "        # Plot slice for the given plane and slice.\n",
    "        self.fig = plt.figure(figsize=self.figsize)\n",
    "        plt.imshow(self.vol[z,:,:], vmin=self.v[0], vmax=self.v[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE.\n",
    "ImageSliceViewer3D(astack);  # semi-colon suppresses text output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Registration\n",
    "In **registration** we use the transformation to align consecutive slices. Here, we will use the **optical flow** to estimate the change in the signal across consecutive slices. We will use *optical_flow_tvl1* in the **skimage.registration** module to calculate the optical flow, and the *warp* function in **skimage.transform** to apply the optical flow field to consecutive slices.\n",
    "\n",
    "First, take a look at the help for both functions and identify their key parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE\n",
    "from skimage import registration as skr\n",
    "\n",
    "skr.optical_flow_tvl1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE\n",
    "from skimage import transform as skt\n",
    "\n",
    "skt.warp?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill in the parameters in the calls to *optical_flow_tvl1* and *warp* below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from skimage import registration as skr\n",
    "from skimage import transform as skt\n",
    "\n",
    "# DELETE THIS CODE.\n",
    "## this here is a toy example to better understand the effect of warp.\n",
    "# astack = astack[0:2]\n",
    "# row_coords, col_coords = np.meshgrid(np.arange(\n",
    "#         astack.shape[1]), np.arange(astack.shape[2]), indexing='ij')\n",
    "#\n",
    "## warp applies the inverse transformation!!\n",
    "# astack[1] = skt.warp(astack[0], numpy.array([row_coords + 2, col_coords + 2]), preserve_range=True)    \n",
    "\n",
    "# create array to store registered image.\n",
    "registered_stack_tvl1 = np.empty(astack.shape)\n",
    "registered_stack_tvl1[0] = astack[0]\n",
    "\n",
    "# create coordinate matrices to use in warp.\n",
    "row_coords, col_coords = np.meshgrid(np.arange(astack.shape[1]), np.arange(astack.shape[2]), indexing='ij')\n",
    "\n",
    "# compute the optical flow: for every slice in the stack\n",
    "for slice_index in range(astack.shape[0]-1): \n",
    "    # compute the optical flow between the current and the next slice: \n",
    "    # this returns the transformation that converts the reference image into the moving image.\n",
    "    # DELETE THIS LINE (the stuff in parentheses)\n",
    "    v, u = skr.optical_flow_tvl1(astack[slice_index], astack[slice_index+1])\n",
    "\n",
    "    # apply optical flow and store transformed image: remember warp applies the inverse transformation!\n",
    "    # DELETE THIS LINE (the stuff in parentheses)\n",
    "    registered_stack_tvl1[slice_index+1] = skt.warp(astack[slice_index+1], np.array([row_coords + v, col_coords + u]), order=5, mode='constant', cval=0, preserve_range=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our helper class above to visualize the registration results in *registered_stack*. What happened? How has the image changed? What is the effect of the *order* and *mode* parameters for *warp*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE\n",
    "ImageSliceViewer3D(registered_stack_tvl1)  \n",
    "\n",
    "# order determines the type of interpolation applied: the greater the order, \n",
    "# the better the results (compare to order 0, nearest neighbour);\n",
    "# mode defines what values are used for padding \n",
    "# (e.g. 'edges' repeats the values around the image edge)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tracking\n",
    "\n",
    "In **tracking** the transformation is used to match object positions across slices and reconstruct their trajectories. We will now use the Lucas-Kanade algorithm implemented in *optical_flow_ilk* in the **skimage.registration** package. Take a look at the help for *optical_flow_ilk*, paying attention to the *radius* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE\n",
    "skr.optical_flow_ilk?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use *optical_flow_ilk* to create and visualize the optical flow field across slices. Interpolating the value of the flow field at any point **p** of the image generates a vector **v** such that **p** + **v** predicts the position of **p** in the next slice. As you can imagine, this is at the base of several tracking algorithms.\n",
    "\n",
    "Examine the code below and complete the code to invoke *optical_flow_ilk*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for quiver plots\n",
    "nvec = 20  # number of vectors to be displayed along each image dimension\n",
    "nr, nc = astack.shape[1:]\n",
    "step = max(nr//nvec, nc//nvec)\n",
    "flow_stack = np.empty((astack.shape[0]-1, 576, 576))  # we'll display figures in 8x8 inches, with 72 pixels/inch.\n",
    "\n",
    "# compute the optical flow: for every slice in the stack\n",
    "for slice_index in range(astack.shape[0]-1): \n",
    "    # compute the optical flow between the current and the next slice.\n",
    "    # DELETE THIS LINE (the stuff in parentheses)\n",
    "    v, u = skr.optical_flow_ilk(astack[slice_index], astack[slice_index+1], radius=7)\n",
    "\n",
    "    # display optical flow\n",
    "    # compute flow magnitude\n",
    "    flow_magnitude = np.sqrt(u ** 2 + v ** 2)\n",
    "\n",
    "    y, x = np.mgrid[:nr:step, :nc:step]\n",
    "    u_ = u[::step, ::step]\n",
    "    v_ = v[::step, ::step]\n",
    "\n",
    "    # create a figure and display the vector field overlaid on an image.\n",
    "    # plt.imshow(flow_magnitude)  # use this instead of next line if you want to visualize the flow magnitude. \n",
    "    fig = plt.figure(figsize=(8, 8), frameon=False, tight_layout=True)\n",
    "    plt.imshow(astack[slice_index])  # use this instead of the line above to visualize the original image. \n",
    "    plt.quiver(x, y, u_, v_, color='r', units='dots', angles='xy', scale=0.25, scale_units='xy', lw=3)\n",
    "    plt.gca().set_axis_off()\n",
    "\n",
    "    # capture figure contents into flow_stack\n",
    "    fig.canvas.draw()\n",
    "    image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    flow_stack[slice_index] = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))[:, :, 0]\n",
    "\n",
    "    # close the figure\n",
    "    plt.close(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our helper class to visualize *flow_stack*. What happens if you use different values for the *radius* parameter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE THIS CODE\n",
    "ImageSliceViewer3D(flow_stack)\n",
    "\n",
    "# radius values that are too small (e.g. 3) lead to  disorganized vector fields;\n",
    "# radius values that are too large (e.g. 128) lead to a uniform vector field;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider how one may use optical flow fields for cell tracking: if we interpolate the optical flow field at the centroid of objects detected in an image, we can predict the position of the objects in the next slice, and identify corresponding objects across slices. Other approaches that integrate segmentation and tracking are also possible, for instance by applying the optical flow to the seeds for watershed segmentation on one slice to identify seeds on the following slices. Objects segmented from matching seeds represent the same object in different slices.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
